Parameter der nächsten 5 Trainings: batch_size = [32, 128, 512, 1024] mit Dropout ... = [256] ohne Dropout
0,0.6436,1.03266090698,0.866,0.426718467379
1,0.9104,0.287385619926,0.9003,0.36670321356
2,0.9504,0.178033381271,0.9308,0.276040683572
3,0.95,0.175473204291,0.9598,0.140656676995
4,0.958,0.145051747308,0.9537,0.153565145567
5,0.97,0.0936292030007,0.9599,0.155413012173
6,0.9788,0.0724847050942,0.9585,0.147373209511
7,0.9844,0.0575995647425,0.945,0.23194599202
8,0.9796,0.0759973481634,0.9615,0.14222208156
9,0.9756,0.0702334381826,0.9634,0.138516704884
10,0.978,0.0766522849679,0.9672,0.124925355984
11,0.9736,0.0914607100096,0.9629,0.148688272673
12,0.9844,0.0509192741424,0.9701,0.134628389781
13,0.9928,0.0227951016644,0.9659,0.166654784086
14,0.9932,0.035058192296,0.9697,0.126324327999
15,0.992,0.0324735373909,0.9641,0.154955502493
16,0.9916,0.0254612072973,0.9651,0.17710270795
17,0.9856,0.0528857120021,0.9636,0.190501281538
18,0.9916,0.0395467829554,0.9657,0.177856617292
19,0.9872,0.0585517296324,0.9666,0.167616317203

0,0.495599999237,1.514006882,0.7621,0.718206589794
1,0.856799999332,0.473115086079,0.9228,0.266188875294
2,0.926799999714,0.250015220642,0.9426,0.186118975973
3,0.953199999237,0.147620192456,0.9439,0.174003249294
4,0.958400000477,0.115323655558,0.9508,0.153522983424
5,0.970800000477,0.088383116734,0.9573,0.136851626964
6,0.977199999619,0.0653468918383,0.9613,0.119321550686
7,0.982799999619,0.0516464585871,0.9609,0.155386418913
8,0.976800000477,0.0721461445332,0.9481,0.1739384951
9,0.9796,0.0576938587807,0.9659,0.122252947313
10,0.9908,0.0337254653894,0.9642,0.134538714201
11,0.9936,0.0226547817811,0.96,0.154863265723
12,0.9896,0.0288273651406,0.9626,0.144025851981
13,0.992399999237,0.0251647683263,0.9653,0.141749807915
14,0.987199999237,0.0484920189857,0.9532,0.176334169177
15,0.990799999619,0.03382202712,0.9611,0.146479254361
16,0.993599999619,0.0170423821926,0.9735,0.121039448261
17,0.9972,0.0089152963385,0.9699,0.137986277719
18,0.992799999619,0.0249071558386,0.973,0.116088016863
19,0.9948,0.017234159179,0.9615,0.146950897724

0,0.245999998474,2.19325023537,0.611000000286,1.60638655491
1,0.511999997902,1.56080798454,0.579400000191,1.2164161747
2,0.588400001049,1.1345386097,0.732400000381,0.944635239029
3,0.768000005341,0.734710696983,0.829400000095,0.554062640667
4,0.848000004959,0.500454679012,0.8771,0.418431055832
5,0.90120000124,0.354209554052,0.911299999714,0.306246310472
6,0.922000004101,0.261095481491,0.925799999905,0.24744654479
7,0.935600001049,0.202552700257,0.936200000381,0.212805015564
8,0.951200004578,0.156316964221,0.938799999237,0.207719485617
9,0.954400001717,0.139117641997,0.946499999619,0.172254139709
10,0.958799996662,0.120414941275,0.949099999237,0.155562474775
11,0.972000002384,0.0975698182344,0.948700000572,0.166347397709
12,0.977199995804,0.0785391273975,0.957899999619,0.133523676014
13,0.979999995136,0.0763113308191,0.956399999619,0.143699162483
14,0.979999995804,0.0575648241222,0.956899999619,0.142131369615
15,0.985599995804,0.0482918891847,0.955300000095,0.155017298245
16,0.985600001526,0.0441002236128,0.9564,0.153250608373
17,0.981600001526,0.0566833139539,0.952199999714,0.182629857016
18,0.986400004387,0.0468747255921,0.9589,0.150989876795
19,0.986400001526,0.0377053292394,0.960500000095,0.146959067941

0,0.130799999905,2.28695663071,0.476500000954,2.14159803238
1,0.405600000381,1.97189083672,0.283599998903,1.84840992413
2,0.398399995232,1.74445637531,0.551000000954,1.39210052147
3,0.572400000763,1.30931957169,0.677300001907,1.08675340424
4,0.707600003242,0.949399370384,0.743700001144,0.779480652618
5,0.763199996281,0.737807007694,0.77030000124,0.767302202606
6,0.800800004482,0.63962649622,0.812400001431,0.598225889874
7,0.811999997902,0.541074781799,0.872300001812,0.436064631224
8,0.875999998569,0.412152282143,0.873700000095,0.411181044483
9,0.897999995518,0.339924184036,0.898900001335,0.317623788881
10,0.911600003433,0.277515252876,0.917999998283,0.266317891836
11,0.933600002575,0.219690753484,0.920700000191,0.257120127463
12,0.938800001049,0.191400202346,0.931999997807,0.218317269659
13,0.945599996662,0.169252376783,0.937800000095,0.196903614354
14,0.952800005245,0.141077539611,0.942600002003,0.183017513633
15,0.962000003052,0.123261840928,0.941300002193,0.183049550128
16,0.962399997997,0.113648676145,0.946999999714,0.166137428641
17,0.968400000858,0.103208976376,0.949800001621,0.156157842422
18,0.974400000191,0.081207149303,0.945599999619,0.177957111883
19,0.972399996471,0.0755907851994,0.953600001431,0.153933677268

0,0.371599999285,1.96782848892,0.5177,1.35293407459
1,0.606799999046,1.18210469761,0.749,0.716540962887
2,0.809600000286,0.616085639334,0.8198,0.512517420959
3,0.891599997807,0.34715871172,0.9173,0.272425399256
4,0.942400001144,0.191050397778,0.9318,0.226989233631
5,0.957600002289,0.145005429459,0.9422,0.187747644496
6,0.971200001335,0.0954339201689,0.9484,0.164046951491
7,0.978000000954,0.0689053327203,0.9515,0.164581070387
8,0.985200000572,0.0483117521882,0.9546,0.158531717199
9,0.988800000381,0.0352577573121,0.9607,0.144030161053
10,0.9924,0.0268042902805,0.9547,0.178393873933
11,0.9964,0.0166255287588,0.9645,0.147652245653
12,0.9984,0.00758856481947,0.9588,0.181234559613
13,0.996400000191,0.00997298173755,0.9402,0.273497943896
14,0.983200000191,0.0574419018924,0.9456,0.231310603376
15,0.972000000572,0.0919549909115,0.9408,0.197513092878
16,0.988400000572,0.0441118696928,0.9574,0.138827900459
17,0.994000000763,0.0195115193367,0.963,0.144449072236
18,0.997200000381,0.0109044998378,0.9692,0.135106845367
19,0.998,0.00626687865146,0.9596,0.193242040993

Parameter der nächsten 3 Trainings: pool_size = [1,3] mit Dropout ... = [1] ohne Dropout
0,0.5376,1.32866754422,0.8115,0.578619429779
1,0.9112,0.316030271354,0.9119,0.286980921692
2,0.952,0.172240887696,0.9379,0.21704367887
3,0.972,0.100689517237,0.9349,0.230266640317
4,0.9772,0.0814272361886,0.9154,0.323097369415
5,0.9756,0.0784409483753,0.935,0.243024591243
6,0.9856,0.0448507606417,0.9351,0.328238646277
7,0.9836,0.0587470352554,0.922,0.270229537722
8,0.9684,0.141507671803,0.9113,0.407544985396
9,0.9784,0.0858964521194,0.9484,0.25058712174
10,0.988,0.0551465258753,0.9139,0.498268150821
11,0.9848,0.050649512148,0.9398,0.306112743925
12,0.99,0.0360348846637,0.9538,0.265468717912
13,0.9928,0.027286327365,0.9297,0.55022174123
14,0.9912,0.0405057245901,0.9509,0.23585397261
15,0.9908,0.0365405029236,0.9509,0.251098041024
16,0.986,0.0589505099488,0.9352,0.387264447051
17,0.9928,0.0369258855347,0.9611,0.200366400176
18,0.9996,0.00121707424109,0.9609,0.319392573972
19,0.9924,0.0557710277291,0.9295,0.350066607884

0,0.124,2.20733381691,0.2273,2.02944663467
1,0.3044,1.65058427963,0.4775,1.36287802486
2,0.5108,1.2425150816,0.6244,0.939936197281
3,0.6792,0.827622687149,0.7866,0.624022551155
4,0.7904,0.577741645774,0.836,0.431937607813
5,0.8744,0.388486988974,0.9089,0.341187598336
6,0.8904,0.391614995956,0.9299,0.281680963522
7,0.9292,0.257035756099,0.947,0.207178399563
8,0.94,0.192620431447,0.9285,0.281424313009
9,0.9448,0.199643460557,0.9496,0.193295384765
10,0.9656,0.127440066195,0.9536,0.184964020303
11,0.956,0.163810189931,0.9574,0.166115568691
12,0.968,0.116980047977,0.9577,0.162256335053
13,0.9668,0.120644021924,0.9584,0.174250944163
14,0.9676,0.117479708309,0.966,0.129648946809
15,0.9772,0.0907578171112,0.9625,0.135786720858
16,0.9784,0.081519385929,0.9578,0.202875407844
17,0.9752,0.0830800335549,0.961,0.169204686616
18,0.97,0.104544792806,0.966,0.139222256305
19,0.9772,0.0772807450503,0.9734,0.108314149999

0,0.6484,1.07754848366,0.8675,0.42709808681
1,0.9348,0.243531014544,0.8977,0.480230493462
2,0.9476,0.199906090093,0.9267,0.23695461576

Parameter der nächsten 4 Trainings: dense_layers = [1,2,4,8]
0,0.6696,0.967865464187,0.8764,0.384851098299
1,0.9188,0.273674793482,0.9446,0.177430405027
2,0.9552,0.14602162986,0.9524,0.158771033529
3,0.9676,0.100520288658,0.9595,0.144170099058
4,0.9756,0.078810292387,0.9368,0.203775544745
5,0.974,0.0638823015309,0.9621,0.126363202178
6,0.9868,0.040610670058,0.9634,0.131857451117
7,0.9828,0.0472799869522,0.9597,0.141461443408
8,0.9864,0.0373357949243,0.9657,0.126928590761
9,0.9908,0.0287477838725,0.9535,0.171703304265
10,0.9864,0.0304117700187,0.9653,0.140363083165
11,0.9904,0.0259036905175,0.9627,0.16248800547
12,0.9924,0.025024749507,0.9681,0.122544528039
13,0.994,0.0166492653135,0.9658,0.136918374388
14,0.9968,0.0109501139611,0.9667,0.144908641849
15,0.9976,0.00795993773351,0.9721,0.120686855683
16,0.9956,0.0153638350986,0.9698,0.124264467298
17,0.996,0.0104665485371,0.9714,0.109894088206
18,0.9968,0.00863032526374,0.9692,0.143917555505
19,0.9964,0.010579557032,0.9621,0.17486113541

0,0.7004,0.933157900369,0.8986,0.326449190044
1,0.9268,0.247520493865,0.9162,0.258468627495
2,0.956,0.156570630456,0.9562,0.139820157599
3,0.9708,0.100693932451,0.9597,0.121687294699
4,0.9776,0.0720745095849,0.9626,0.127361588149
5,0.9796,0.0597052313566,0.9487,0.181743994682
6,0.9804,0.0607756273114,0.9594,0.145411051369
7,0.9848,0.0435878116939,0.9593,0.167297970975
8,0.9876,0.0373847053706,0.9505,0.196991593032
9,0.9892,0.0311327390801,0.9566,0.168638007238
10,0.986,0.0421935127466,0.954,0.165377863465
11,0.9908,0.0248879749858,0.9678,0.127720080767
12,0.992,0.0223597518785,0.9637,0.152281325789
13,0.9904,0.0255227311637,0.967,0.134753680542
14,0.9924,0.0313889979046,0.9718,0.103245063118
15,0.9944,0.0129143343512,0.9708,0.117454793303
16,0.9944,0.0133051129326,0.969,0.121177515133
17,0.992,0.0228571929493,0.9675,0.135029595239
18,0.9932,0.0194536767957,0.9675,0.129406614122
19,0.9976,0.00681155636301,0.9616,0.176989695682

0,0.5492,1.32016830454,0.8114,0.577403843021
1,0.8984,0.330755691528,0.9169,0.273713847882
2,0.9288,0.224722627419,0.9374,0.201136772764
3,0.9528,0.158051846482,0.9443,0.191840687719
4,0.9708,0.100974858809,0.9502,0.168985564613
5,0.9728,0.0865416051865,0.947,0.193917615595
6,0.9564,0.144353501389,0.951,0.172642131051
7,0.9796,0.0541836030894,0.9516,0.177318725396
8,0.9824,0.0664287421547,0.9681,0.106995147994
9,0.9888,0.0322718546823,0.9686,0.112582155401
10,0.9948,0.0187140117165,0.9692,0.124625854264
11,0.99,0.0247286776252,0.9602,0.161730972509
12,0.9684,0.111358779946,0.9602,0.170920928364
13,0.988,0.0384202229664,0.958,0.179355594228
14,0.9872,0.0448479682339,0.968,0.123352955563
15,0.9928,0.0282068199654,0.9661,0.151752274888
16,0.9952,0.020333821518,0.9715,0.122726308154
17,0.9972,0.00881928147338,0.9643,0.163755405149
18,0.9956,0.0118218674835,0.9753,0.118186510232
19,0.9936,0.022598239252,0.9724,0.126363008634

0,0.2976,1.87198555355,0.488,1.42398216743
1,0.6372,0.943280035305,0.7535,0.666714667988
2,0.8424,0.484127461559,0.7758,0.709755705738
3,0.9072,0.337941456244,0.9318,0.24781420884
4,0.9416,0.240058168912,0.9401,0.235179467639
5,0.9588,0.159290617561,0.9392,0.237464105928
6,0.964,0.152152214086,0.9561,0.19431281108
7,0.9768,0.0935676873893,0.947,0.260786144614
8,0.9712,0.119519152042,0.9534,0.202847990537
9,0.9764,0.0977313802838,0.9549,0.210497525278
10,0.9704,0.111110957623,0.9493,0.239208426534
11,0.9776,0.092408376503,0.9617,0.171181204277
12,0.9684,0.120417567263,0.9501,0.229784131856
13,0.9732,0.11897961269,0.9397,0.260665525781
14,0.9796,0.087999043718,0.9523,0.266185350442
15,0.9844,0.0835140895724,0.9543,0.231252668216
16,0.9856,0.0695014835447,0.9534,0.260359971726
17,0.9864,0.0675686608016,0.9641,0.198650806703
18,0.9752,0.118675430808,0.9473,0.294994248656
19,0.9804,0.0954265157003,0.9648,0.169161022083

Parameter der nächsten 6 Trainings: neurons_in_dense_layer=ii = [8, 16, 64, 256, 1024, 2048]
0,0.278,2.08474994354,0.3432,1.8350837204
1,0.4004,1.6644558712,0.4331,1.51300262299
2,0.458,1.44851723566,0.5186,1.34321324635
3,0.53,1.27666400013,0.5637,1.22013986721
4,0.5516,1.1685731039,0.625,0.98485638628
5,0.736,0.783341580582,0.7999,0.680276907158
6,0.8332,0.589348082256,0.8645,0.512462660122
7,0.884,0.404303770256,0.8686,0.458336509371
8,0.9052,0.339449994659,0.9082,0.339701261091
9,0.9284,0.272949827147,0.9174,0.309120296049
10,0.9456,0.210511278152,0.9218,0.299788677204
11,0.946,0.211949389243,0.9301,0.267146104461
12,0.952,0.169001838636,0.9339,0.250587910688
13,0.9576,0.157624381742,0.9352,0.256899876904
14,0.964,0.137795892777,0.9359,0.244869756016
15,0.9668,0.122350651719,0.934,0.248470994809
16,0.9676,0.108947972117,0.9405,0.244805661455
17,0.97,0.10966835165,0.9415,0.232315079454
18,0.9712,0.0923977681071,0.9423,0.233921583538
19,0.9724,0.0926874208895,0.9396,0.242709336608

0,0.4024,1.73461836586,0.6994,0.902202173615
1,0.7808,0.666505882072,0.8766,0.425466104794
2,0.8976,0.365662736511,0.9009,0.343878284192
3,0.9284,0.260786014414,0.9336,0.235842381603
4,0.9428,0.203155789512,0.9413,0.207215679079
5,0.9656,0.138703433847,0.9324,0.235279756203
6,0.9464,0.166053347445,0.9477,0.175541898894
7,0.9672,0.119133818145,0.9474,0.183292356424
8,0.9736,0.0874766844481,0.9597,0.141008583003
9,0.982,0.0665562058449,0.9488,0.18934190236
10,0.9788,0.0605517087996,0.9587,0.143289188864
11,0.9664,0.112221388586,0.9561,0.160509003809
12,0.9792,0.066166978713,0.9592,0.138896378435
13,0.99,0.0321138151586,0.964,0.136843979849
14,0.9932,0.0234144848257,0.9625,0.149755476835
15,0.9888,0.0394512715838,0.9549,0.172321308927
16,0.9896,0.0286621909446,0.9611,0.15950553759
17,0.9864,0.032268524581,0.9576,0.162761272458
18,0.99,0.0280050731599,0.9623,0.143976054186
19,0.9956,0.0175087975681,0.9617,0.175014595227

0,0.55,1.33938144922,0.8539,0.506511783028
1,0.8852,0.39007956624,0.9031,0.325613059974
2,0.9292,0.246957550931,0.9391,0.19955546267
3,0.946,0.181943746185,0.9463,0.168217579308
4,0.952,0.156052399141,0.9434,0.187414099246
5,0.9696,0.0976024778903,0.9566,0.148652280714
6,0.9788,0.0764763005438,0.9618,0.125355049483
7,0.9812,0.0631310369819,0.9641,0.127588683026
8,0.9808,0.0554514072157,0.9592,0.144650604998
9,0.9804,0.0577085753504,0.9566,0.161889034846
10,0.9852,0.0444105742246,0.9617,0.148190236443
11,0.9804,0.0597873707578,0.9575,0.141516740808
12,0.9916,0.0304487256907,0.9669,0.124685656734
13,0.9936,0.0203391477793,0.9601,0.178380991845
14,0.9772,0.0697576470614,0.9546,0.163900025708
15,0.9908,0.0351603800557,0.9638,0.14108800591
16,0.9928,0.0283804013878,0.9648,0.141521409429
17,0.9932,0.0258418576628,0.9679,0.135845495569
18,0.9912,0.0307742202644,0.9465,0.272411697625
19,0.9896,0.030030465741,0.962,0.148735321993

0,0.6236,1.12781750238,0.8332,0.512486036587
1,0.91,0.31435075264,0.9403,0.198097205064
2,0.9508,0.167437870085,0.9369,0.196451313567
3,0.9636,0.115258504638,0.9482,0.164188425422
4,0.9784,0.0860121943831,0.9505,0.165323171132
5,0.976,0.073075522344,0.9551,0.147683521241
6,0.9784,0.0679444025278,0.9513,0.172104284274
7,0.956,0.122251638842,0.9638,0.117460070357
8,0.9736,0.0863535676926,0.9665,0.10994998513
9,0.99,0.0344549710412,0.9608,0.154222449217
10,0.9932,0.0218264292236,0.9654,0.151950129299
11,0.9944,0.022185573954,0.966,0.137005829316
12,0.9912,0.030230430021,0.9695,0.119078451101
13,0.9964,0.00955422854244,0.9689,0.135999110293
14,0.9948,0.0154698053565,0.9696,0.125352221914
15,0.9968,0.0133577197002,0.9711,0.12661045435
16,0.9968,0.00914515789971,0.9667,0.152619244733
17,0.994,0.017693709844,0.9619,0.155701077925
18,0.9948,0.0167589304165,0.9695,0.125123233874
19,0.9932,0.0175926180348,0.9675,0.140532988097

0,0.686,0.98835615809,0.9092,0.289478123534
1,0.9196,0.260870653832,0.9488,0.160943479484
2,0.9572,0.133358604403,0.9571,0.142385686504
3,0.9696,0.0926341309629,0.9594,0.143710682994
4,0.9788,0.0730619593685,0.9624,0.11868738042
5,0.9844,0.0519993785083,0.9569,0.141196757871
6,0.984,0.0433249098406,0.9599,0.161585905459
7,0.9828,0.0588475764394,0.958,0.148328654663
8,0.9856,0.0438191252246,0.9601,0.136849698843
9,0.9856,0.0420108751724,0.9683,0.130925842292
10,0.994,0.0187832139528,0.9632,0.143393349589
11,0.994,0.0211657001204,0.9708,0.112067945953
12,0.9948,0.0142253978321,0.9638,0.172730241982
13,0.9904,0.0215819860258,0.9616,0.16894039706
14,0.9932,0.0211810459615,0.9516,0.210364712654
15,0.9904,0.0270726693137,0.9558,0.208985807113
16,0.9956,0.0130042559804,0.9685,0.136956714132
17,0.9956,0.015415946021,0.962,0.197968038854
18,0.9932,0.0278194225797,0.9679,0.12532471566
19,0.998,0.00635697312765,0.9699,0.158801606159

0,0.7088,0.896364592123,0.8756,0.36283959713
1,0.9252,0.238361133273,0.9304,0.218392884967
2,0.9652,0.117843542896,0.9571,0.138606787231
3,0.97,0.0993318398952,0.9632,0.118822870225
4,0.9772,0.0700710839033,0.9453,0.202975719683
5,0.9736,0.08408076627,0.9637,0.135215137982
6,0.9864,0.0461313274797,0.9395,0.238052553172
7,0.9812,0.0507729719459,0.9659,0.13012834098
8,0.9824,0.0547965705972,0.9613,0.145532725753
9,0.9864,0.0387517088356,0.9701,0.115254845144
10,0.9952,0.0150612170327,0.971,0.122761151729
11,0.9956,0.0164270612068,0.9726,0.115312417962
12,0.9952,0.0109466816106,0.9595,0.191894017353
13,0.9892,0.0332040187102,0.9684,0.121909393322
14,0.996,0.0096255518673,0.9671,0.16554784969
15,0.9972,0.0100357821017,0.9724,0.11146901042
16,0.9976,0.00847184290402,0.9609,0.176048029684
17,0.9952,0.023939979339,0.9692,0.130468072532
18,0.996,0.0143142011594,0.9704,0.12928009188
19,0.9948,0.0244099044997,0.9614,0.190450884084

